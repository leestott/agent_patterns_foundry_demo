# ── Foundry Local ─────────────────────────────────────────────────────────────
# Leave FOUNDRY_LOCAL_ENDPOINT blank to auto-detect via `foundry service status`
# Only set to override (e.g. if running on a non-default port)
# FOUNDRY_LOCAL_ENDPOINT=http://localhost:<dynamic-port>/v1
FOUNDRY_MODEL=qwen2.5-1.5b

# Optional: API key (Foundry Local doesn't require one, but OpenAI client needs a placeholder)
FOUNDRY_API_KEY=foundry-local

# ── Microsoft Foundry Cloud ────────────────────────────────────────────────────
# Set MODEL_PROVIDER=azure_foundry to use Microsoft Foundry instead of Foundry Local
MODEL_PROVIDER=foundry_local

AZURE_FOUNDRY_ENDPOINT=https://<your-project>.openai.azure.com/
AZURE_FOUNDRY_API_KEY=<your-api-key>
AZURE_FOUNDRY_MODEL=gpt-4o-mini
# If using Azure OpenAI deployments, set the deployment name (otherwise leave blank)
AZURE_FOUNDRY_DEPLOYMENT=

# ── UI configuration ───────────────────────────────────────────────────────────
UI_PORT=8765
